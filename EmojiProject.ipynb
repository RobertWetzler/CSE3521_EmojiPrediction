{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmojiProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mIJdo6BZcXR"
      },
      "source": [
        "# links for training data, labels, and mapping\n",
        "es_training = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/es_trial.text'\n",
        "es_training_labels = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/es_trial.labels'\n",
        "us_test = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_test.text'\n",
        "es_test = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/es_test.text'\n",
        "us_test_label = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_test.labels'\n",
        "es_test_label = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/es_test.labels'\n",
        "es_mapping = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/es_mapping.txt'\n",
        "us_mapping = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_mapping.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDNz_wvaPmG"
      },
      "source": [
        "def getListForLabel(df_train, num):\n",
        "  \"\"\"Returns a list of the tweets corresponding to a label\n",
        "  \n",
        "  :param df_train: dataframe to extract tweets from\n",
        "  :param num: emoji label number\n",
        "  :rtype: list\n",
        "  :return: list consisting of tweets who have the label num\n",
        "  \"\"\"\n",
        "  return df_train[df_train[df_train.columns[0]] == num].iloc[:, 1].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy-FrnLBhGhA"
      },
      "source": [
        "def classVocab(train,vocab, vocab_class):\n",
        "  \"\"\"Returns number of words in a class\n",
        "  \n",
        "  :param train: list containing all tweets for a class\n",
        "  :param vocab: dictionary of all unique words\n",
        "  :param vocab_class: list of unique words for a class\n",
        "  :rtype: int\n",
        "  :return: int representing the number of words in the class\n",
        "  \"\"\"\n",
        "  total_words_class = 0\n",
        "  for sent in train:\n",
        "    word_list = sent.split()\n",
        "    for word in word_list:\n",
        "      total_words_class+=1\n",
        "      if word in vocab:\n",
        "        vocab[word]+=1\n",
        "      else:\n",
        "        vocab[word]=1\n",
        "      if word in vocab_class: #dictionary of class vocab\n",
        "        vocab_class[word]+= 1\n",
        "      else:\n",
        "        vocab_class[word] = 1\n",
        "  return total_words_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufHAFx5-CTQY"
      },
      "source": [
        "def trainData(training_data_df, num_classes): #replace str_i with i\n",
        "  \"\"\"Returns number of words in a class\n",
        "  \n",
        "  :param training_data_df: df containing all tweets and their corresponding labels\n",
        "  :param num_classes: number of classes\n",
        "  :rtype: dict\n",
        "  :return: dict containing probability, vocab, and # of words in each class along with vocab size\n",
        "  \"\"\"\n",
        "  training_data = {} #holds data for each class (eg. PositiveTrain or PositiveTest) \n",
        "  num_sentences_per_class = {} #number of sentences per class \n",
        "  class_probability = {} #class probability \n",
        "  vocab = {} #unique words (+counts)\n",
        "  vocab_class = {} #nested dict #vocab words in each class \n",
        "  words_in_class = {} # # of total words in each class \n",
        "  total_num_sentences = 0 #total number of sentences in all classes combined\n",
        "  \n",
        "  for i in range(num_classes):\n",
        "    training_data[i] = getListForLabel(training_data_df, i) #isolate rows based on label\n",
        "    num_sentences_per_class[i] = len(training_data[i]) #number of sentences in the clasentences\n",
        "    total_num_sentences += num_sentences_per_class[i] #add to total number of sentences\n",
        "    vocab_class[i] = {}\n",
        "    words_in_class[i] = classVocab(training_data[i], vocab, vocab_class[i])\n",
        "  \n",
        "  vocab_size = len(vocab.keys()) #number of unique words \n",
        "\n",
        "  for i in range(num_classes):\n",
        "    class_probability[i] = num_sentences_per_class[i]/total_num_sentences #probability of a class\n",
        " #probability of a class\n",
        "  \n",
        "  return {'class prob' : class_probability, 'vocab class': vocab_class, 'words_in_class' : words_in_class, 'vocab size': vocab_size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mw_Hbi4BGGS"
      },
      "source": [
        "def prediction(test_dict, prob_class, vocab_class, total_words_class, vocab_size, num_classes, alpha):\n",
        "  \"\"\"Returns list with predictions\n",
        "  \n",
        "  :param test_dict: dict containing tweets for each class; key = class, value = list of tweets\n",
        "  :param prob_class: dict containing probability of each class; key = class, value = probability of class\n",
        "  :param vocab_class: dict containing vocab words for each class; key = class, value = list of words in the class\n",
        "  :param total_words_class: dict containing number of words for each class; key = class, value = # of words in the class\n",
        "  :param vocab_size: number of vocab words\n",
        "  :param num_classes: number of classes\n",
        "  :param alpha: alpha value\n",
        "  :rtype: list\n",
        "  :return: list containing tuples of sentences with their actual and predicted labels\n",
        "  \"\"\"\n",
        "  prediction_list = []\n",
        "  for i in range(num_classes):\n",
        "    for sent in test_dict[i]:\n",
        "      prob_list = []\n",
        "      word_list = sent.split()\n",
        "      actual_sentiment = i\n",
        "      for j in range(num_classes):\n",
        "        prob_list.append(find_prob(word_list,prob_class[j], vocab_class[j], total_words_class[j], vocab_size, alpha))\n",
        "      pred_sentiment = prob_list.index(max(prob_list))\n",
        "      pred=(sent, actual_sentiment, pred_sentiment)\n",
        "      prediction_list.append(pred)\n",
        "  return prediction_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYTo-VdMqaYU"
      },
      "source": [
        "def find_prob(list_words, prob_class, vocab_class, total_words_class, total_words, alpha):\n",
        "  \"\"\"Returns list with predictions\n",
        "  \n",
        "  :param list_words: list of words in a sentence\n",
        "  :param prob_class: probability of the class\n",
        "  :param vocab_class: vocab words in the class\n",
        "  :param total_words_class: number of words in the class\n",
        "  :param total_words: total number of words\n",
        "  :param alpha: alpha value\n",
        "  :rtype: float\n",
        "  :return: probability that the sentence is in a certain class\n",
        "  \"\"\"\n",
        "  sent_prob = prob_class\n",
        "  for word in list_words:\n",
        "    if word in vocab_class:\n",
        "      numerator = vocab_class[word] + alpha\n",
        "    else:\n",
        "      numerator = alpha\n",
        "    denominator = total_words_class + alpha* total_words\n",
        "    word_prob = numerator / denominator\n",
        "    sent_prob = sent_prob * word_prob\n",
        "  return sent_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlxRYDSuwpE"
      },
      "source": [
        "def test(prediction_list):\n",
        "  \"\"\"Prints accuracy of predictions\n",
        "\n",
        "  :param prediction_list: list of predictions\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  total_test_sample = 0\n",
        "  for pred in prediction_list:\n",
        "    total_test_sample +=1 \n",
        "    (sent, actual_sentiment, pred_sentiment) = pred\n",
        "    if actual_sentiment == pred_sentiment:\n",
        "      correct +=1  \n",
        "  accuracy = correct/total_test_sample\n",
        "  print(\"accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwyrdN9fBkDN"
      },
      "source": [
        "import pandas as pd\n",
        "def getData(text_url, label_url):\n",
        "  \"\"\"Returns df with the tweets and their corresponding labels, and the number of classes\n",
        "\n",
        "  :param text_url: url containing tweets\n",
        "  :param label_url: url containing labels for the tweets\n",
        "  :rtype: df, int\n",
        "  :return: df with tweets+labels, and number of classes\n",
        "  \"\"\"\n",
        "  df =  pd.read_fwf(us_training, header = None)\n",
        "  labels = pd.read_csv(label_url, delimiter = \"\\n\", header = None, error_bad_lines=False)\n",
        "\n",
        "  data = pd.concat([labels, df], axis = 1, ignore_index=True)\n",
        "  data = data.dropna(axis='columns')\n",
        "  return data, len(pd.unique(data.iloc[:, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meQTl0aphulM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75449ef-a3ad-43cc-b5d2-9928c9cb4131"
      },
      "source": [
        "#MAIN METHOD#\n",
        "import pandas as pd\n",
        "us_training = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_trial.text'\n",
        "us_training_labels = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_trial.labels'\n",
        "us_test = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_test.text'\n",
        "us_test_labels = 'https://raw.githubusercontent.com/RobertWetzler/CSE3521_EmojiPrediction/main/us_test.labels'\n",
        "\n",
        "us_training_data, num_classes = getData(us_training, us_training_labels)\n",
        "combo_dict = trainData(us_training_data, num_classes)\n",
        "\n",
        "test_data = {}\n",
        "us_test_data, num_classes = getData(us_test, us_test_labels)\n",
        "for i in range(num_classes):\n",
        "    test_data[i] = getListForLabel(us_test_data, i) #isolate rows based on label\n",
        "predictions = prediction(test_data, combo_dict['class prob'], combo_dict['vocab class'], combo_dict['words_in_class'], combo_dict['vocab size'], num_classes, 10)\n",
        "test(predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.2123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvYx5G11RYrO"
      },
      "source": [
        "BELOW:\n",
        "WIP; taking input tweet from user and outputting the predicted emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juy5Yq89ep5C",
        "outputId": "2464607e-3c45-4b50-a1f7-a9ab2814939f"
      },
      "source": [
        "emojis = {\n",
        "0:\t'â¤',\n",
        "1:\t'ðŸ˜',\n",
        "2:\t'ðŸ˜‚',\n",
        "3:\t'ðŸ’•',\n",
        "4:\t'ðŸ”¥',\n",
        "5:\t'ðŸ˜Š',\t\n",
        "6:\t'ðŸ˜Ž',\n",
        "7:\t'âœ¨',\n",
        "8:\t'ðŸ’™',\t\n",
        "9:\t'ðŸ˜˜',\n",
        "10:\t'ðŸ“·',\n",
        "11:\t'ðŸ‡ºðŸ‡¸',\n",
        "12:\t'â˜€',\n",
        "13:\t'ðŸ’œ',\n",
        "14:\t'ðŸ˜‰',\t\n",
        "15:\t'ðŸ’¯',\t\n",
        "16:\t'ðŸ˜',\n",
        "17:\t'ðŸŽ„',\t\n",
        "18:\t'ðŸ“¸',\n",
        "19:\t'ðŸ˜œ'\n",
        "}\n",
        "text = \".\"\n",
        "while len(text) > 0:\n",
        "  text = input(\"Enter your tweet: \")\n",
        "  # predict somehow\n",
        "  # print predicted emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your tweet: \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}